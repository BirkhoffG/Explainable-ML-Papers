# Papers on Explainable Machine Learning

> Motivated from this [GitHub repository](https://github.com/anguyen8/XAI-papers) with different focus. Papers marked in **bold** are recommended by myself.

## 1. General Idea

### Survey

- Explaining Explanations: An Overview of Interpretability of Machine Learning. *Gilpin et al. 2019* [pdf](https://arxiv.org/pdf/1806.00069.pdf)
- **Interpretable machine learning: definitions, methods, and applications. *Murdoch et al. 2019*** [pdf](https://arxiv.org/pdf/1901.04592v1.pdf) 

### Understanding Interpretability

- The Mythos of Model Interpretability. *Lipton, 2016* [pdf](https://arxiv.org/abs/1606.03490)

- Towards A Rigorous Science of Interpretable Machine Learning. *Doshi-Velez & Kim. 2017* [pdf](https://arxiv.org/pdf/1702.08608.pdf)

## 2. Interpretable Models

- Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission. *Caruana et. al., 2015* [pdf](https://dl.acm.org/doi/pdf/10.1145/2783258.2788613) | [InterpretableML](https://github.com/interpretml/interpret)
  - GAM-based
- Interpretable Decision Sets: A Joint Framework for Description and Prediction. *Lakkaraju et. al., 2016* [pdf](https://dl.acm.org/doi/pdf/10.1145/2939672.2939874)
  - Rule based

## 3. Understanding Black Box Models

> Post hoc interpretability
>

- Interpretability Beyond Feature Attribution:  Quantitative Testing with Concept Activation Vectors (TCAV), *Kim et. al. 2018* [pdf](http://proceedings.mlr.press/v80/kim18d/kim18d.pdf)
- Faithful and Customizable Explanations of Black Box Models. *Lakkaraju et. al. 2019* [pdf](https://dl.acm.org/doi/pdf/10.1145/3306618.3314229)

### Feature Importance

- 



## 4. Explainable ML for Human

> XAI for HCI

- Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning. Kaur et. al., 2019 [pdf](https://dl.acm.org/doi/pdf/10.1145/3313831.3376219)
- Explaining models: an empirical study of how explanations impact fairness judgment. Dodge et. al., 2019 [pdf](https://arxiv.org/pdf/1901.07694.pdf)
- Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making. Cai et. al, 2019 [pdf](https://dl.acm.org/doi/pdf/10.1145/3290605.3300234)
- **Designing Theory-Driven User-Centric Explainable AI. *Wang et. al., 2019*** [pdf](https://dl.acm.org/doi/pdf/10.1145/3290605.3300831)
- Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance. Shen et. al., 2020 [pdf](https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf)

### Interactive ML

- Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models. *Krause et. al., 2016* [pdf](https://dl.acm.org/doi/pdf/10.1145/2858036.2858529)

## 5. Evaluate Interpretability

- Human Evaluation of Models Built for Interpretability.  *Lage et. al., 2019* [pdf](https://aaai.org/ojs/index.php/HCOMP/article/view/5280/5132)



## 6. Others

### Medical Application

- AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration. Ma et. al., 2020 [pdf](https://www.aaai.org/ojs/index.php/AAAI/article/download/5427/5283)
  - RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records. Kwon et. al., 2018 [pdf](https://ieeexplore.ieee.org/iel7/2945/4359476/08440842.pdf)



## Useful Resources

### Courses

- [Interpretability and Explainability in Machine Learning, Fall 2019](https://interpretable-ml-class.github.io/) @ Harvard University (Hima Lakkaraju)

### Toolbox

- InterpretML [GitHub](https://github.com/interpretml/interpret)