# Papers on Explainable Machine Learning

> Motivated from this [GitHub repository](https://github.com/anguyen8/XAI-papers) with different focus. Papers marked in **bold** are recommended by myself.

## Table of Content
- [Papers on Explainable Machine Learning](#papers-on-explainable-machine-learning)
  - [Table of Content](#table-of-content)
  - [1. General Idea](#1-general-idea)
    - [Survey](#survey)
    - [Understanding Interpretability](#understanding-interpretability)
  - [2. Interpretable Models](#2-interpretable-models)
  - [3. Understanding Black Box Models](#3-understanding-black-box-models)
    - [Feature Importance](#feature-importance)
  - [4. Explainable ML for Human](#4-explainable-ml-for-human)
    - [Interactive ML](#interactive-ml)
  - [5. Evaluate Interpretability](#5-evaluate-interpretability)
  - [6. Others](#6-others)
    - [Medical Application](#medical-application)
  - [Useful Resources](#useful-resources)
    - [Courses](#courses)
    - [Toolbox](#toolbox)

## 1. General Idea

### Survey

- Explaining Explanations: An Overview of Interpretability of Machine Learning. *Gilpin et al. 2019* [pdf](https://arxiv.org/pdf/1806.00069.pdf)
  <details><summary>notes</summary>
  </details>

- **Interpretable machine learning: definitions, methods, and applications. *Murdoch et al. 2019*** [pdf](https://arxiv.org/pdf/1901.04592v1.pdf) 
  <details><summary>notes</summary>
  </details>

### Understanding Interpretability

- The Mythos of Model Interpretability. *Lipton, 2016* [pdf](https://arxiv.org/abs/1606.03490)
  <details><summary>notes</summary>
  </details>

- Towards A Rigorous Science of Interpretable Machine Learning. *Doshi-Velez & Kim. 2017* [pdf](https://arxiv.org/pdf/1702.08608.pdf)
  <details><summary>notes</summary>
  </details>

## 2. Interpretable Models

- Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission. *Caruana et. al., 2015* [pdf](https://dl.acm.org/doi/pdf/10.1145/2783258.2788613) | [InterpretableML](https://github.com/interpretml/interpret)
  <details><summary>notes</summary>

  - GAM-based
  </details>
- Interpretable Decision Sets: A Joint Framework for Description and Prediction. *Lakkaraju et. al., 2016* [pdf](https://dl.acm.org/doi/pdf/10.1145/2939672.2939874)
  <details><summary>notes</summary>

  - Rule based
  </details>

## 3. Understanding Black Box Models

> Post hoc interpretability
>

- Interpretability Beyond Feature Attribution:  Quantitative Testing with Concept Activation Vectors (TCAV), *Kim et. al. 2018* [pdf](http://proceedings.mlr.press/v80/kim18d/kim18d.pdf)
  <details><summary>notes</summary>
  </details>

- Faithful and Customizable Explanations of Black Box Models. *Lakkaraju et. al. 2019* [pdf](https://dl.acm.org/doi/pdf/10.1145/3306618.3314229)
  <details><summary>notes</summary>
  </details>

### Feature Importance

- 



## 4. Explainable ML for Human

> XAI for HCI

- Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning. Kaur et. al., 2019 [pdf](https://dl.acm.org/doi/pdf/10.1145/3313831.3376219)
  <details><summary>notes</summary>
  </details>

- Explaining models: an empirical study of how explanations impact fairness judgment. Dodge et. al., 2019 [pdf](https://arxiv.org/pdf/1901.07694.pdf)
  <details><summary>notes</summary>
  </details>

- Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making. Cai et. al, 2019 [pdf](https://dl.acm.org/doi/pdf/10.1145/3290605.3300234)
  <details><summary>notes</summary>
  </details>

- **Designing Theory-Driven User-Centric Explainable AI. *Wang et. al., 2019*** [pdf](https://dl.acm.org/doi/pdf/10.1145/3290605.3300831)
  <details><summary>notes</summary>
  </details>

- Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance. Shen et. al., 2020 [pdf](https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf)
  <details><summary>notes</summary>
  </details>


### Interactive ML

- Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models. *Krause et. al., 2016* [pdf](https://dl.acm.org/doi/pdf/10.1145/2858036.2858529)
  <details><summary>notes</summary>
  </details>

## 5. Evaluate Interpretability

- Human Evaluation of Models Built for Interpretability.  *Lage et. al., 2019* [pdf](https://aaai.org/ojs/index.php/HCOMP/article/view/5280/5132)
  <details><summary>notes</summary>
  </details>



## 6. Others

### Medical Application

- AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration. Ma et. al., 2020 [pdf](https://www.aaai.org/ojs/index.php/AAAI/article/download/5427/5283)
  <details><summary>notes</summary>
  </details>

- RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records. Kwon et. al., 2018 [pdf](https://ieeexplore.ieee.org/iel7/2945/4359476/08440842.pdf)
  <details><summary>notes</summary>
  </details>



## Useful Resources

### Courses

- [Interpretability and Explainability in Machine Learning, Fall 2019](https://interpretable-ml-class.github.io/) @ Harvard University (Hima Lakkaraju)
  <details><summary>notes</summary>
  </details>


### Toolbox

- InterpretML [GitHub](https://github.com/interpretml/interpret)
  <details><summary>notes</summary>
  </details>
